{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fuFFtwvpkDh"
      },
      "outputs": [],
      "source": [
        "!pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, LabelEncoder\n",
        "from sklearn.linear_model import Lasso, ElasticNet\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Fetch the dataset\n",
        "drug_reviews_drugs_com = fetch_ucirepo(id=462)"
      ],
      "metadata": {
        "id": "B3fiVlbwyjit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Extract features and inspect the dataset\n",
        "X = drug_reviews_drugs_com.data.features\n",
        "print(\"Features DataFrame:\\n\", X.head())\n",
        "\n",
        "# Inspect columns to find the target variable\n",
        "print(\"Columns in the dataset:\\n\", X.columns)\n",
        "\n",
        "# Assuming 'rating' or a similar column is the target variable based on common knowledge of the dataset\n",
        "target_column = 'rating'  # Adjust if the actual target is different\n",
        "y = X[target_column]\n",
        "\n",
        "# Drop the target from the features\n",
        "X = X.drop(columns=[target_column])\n",
        "\n",
        "# Print metadata and variable information\n",
        "print(drug_reviews_drugs_com.metadata)\n",
        "print(drug_reviews_drugs_com.variables)"
      ],
      "metadata": {
        "id": "IK_zW9Y-ylN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Preprocess the data\n",
        "# Handle text data: Let's assume there is a text column 'review' to be vectorized using TF-IDF\n",
        "textual_data_column = 'review'  # Adjust this if the actual text column has a different name\n",
        "\n",
        "# Text Vectorization using TF-IDF\n",
        "if textual_data_column in X.columns:\n",
        "    tfidf = TfidfVectorizer(stop_words='english', max_features=1000)\n",
        "    X_text = tfidf.fit_transform(X[textual_data_column]).toarray()\n",
        "    X_text_df = pd.DataFrame(X_text, columns=tfidf.get_feature_names_out())\n",
        "    X = X.drop(columns=[textual_data_column])\n",
        "    X = pd.concat([X, X_text_df], axis=1)\n",
        "\n",
        "# Convert categorical variables to dummy variables\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Visualize distribution of the target variable\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(y, kde=True, bins=20)\n",
        "plt.title(\"Target Variable Distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rdvvmGDFynJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Helper function to create a model pipeline\n",
        "def build_model(model):\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),  # Standardize features\n",
        "        ('poly', PolynomialFeatures(degree=2, include_bias=False)),  # Polynomial features\n",
        "        ('regressor', model)  # Regression model\n",
        "    ])\n",
        "    return pipeline\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    \"Lasso Regression\": Lasso(alpha=0.1),\n",
        "    \"ElasticNet Regression\": ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
        "}"
      ],
      "metadata": {
        "id": "ylpLfnF8yox2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train models and evaluate metrics\n",
        "for name, model in models.items():\n",
        "    # Train the model\n",
        "    pipeline = build_model(model)\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    cross_val_r2 = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2').mean()\n",
        "\n",
        "    # Residuals Plot\n",
        "    residuals = y_test - y_pred\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.scatterplot(x=y_pred, y=residuals)\n",
        "    plt.hlines(y=0, xmin=min(y_pred), xmax=max(y_pred), colors='red', linestyles='dashed')\n",
        "    plt.xlabel(\"Predicted Values\")\n",
        "    plt.ylabel(\"Residuals\")\n",
        "    plt.title(f\"Residuals Plot for {name}\")\n",
        "    plt.show()\n",
        "\n",
        "    # Prediction vs Actual Plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.scatterplot(x=y_test, y=y_pred)\n",
        "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', lw=2)\n",
        "    plt.xlabel(\"Actual Values\")\n",
        "    plt.ylabel(\"Predicted Values\")\n",
        "    plt.title(f\"Actual vs Predicted Values for {name}\")\n",
        "    plt.show()\n",
        "\n",
        "    # Learning Curve Plot\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        pipeline, X_train, y_train, cv=5, scoring='r2', n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 50))\n",
        "\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color='blue', label='Training score')\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color='red', label='Cross-validation score')\n",
        "    plt.title(f\"Learning Curve for {name}\")\n",
        "    plt.xlabel(\"Training Set Size\")\n",
        "    plt.ylabel(\"R^2 Score\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "lVDHeom2yqdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print metrics\n",
        "print(f\"{name} Metrics:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R^2 Score: {r2}\")\n",
        "print(f\"Cross-Validation R^2 Score: {cross_val_r2}\")\n",
        "print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "7JA4RMmfytyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mZkn05Nqy9BS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}